import tkinter as tk
from tkinter import filedialog, messagebox, ttk
import pandas as pd
from urllib.parse import urlparse, parse_qs
from datetime import datetime
from googleapiclient.discovery import build

API_KEY = "xxx"
YOUTUBE = build("youtube", "v3", developerKey=API_KEY)

def extract_video_id(url):
    parsed = urlparse(url)
    if 'youtu.be' in parsed.netloc:
        return parsed.path.strip('/')
    if 'youtube.com' in parsed.netloc:
        qs = parse_qs(parsed.query)
        return qs.get('v', [None])[0]
    return None

def extract_channel_id(url):
    if "/channel/" in url:
        return url.split("/channel/")[1].split("/")[0]
    path = urlparse(url).path.strip("/")
    if path.startswith("user/") or path.startswith("c/") or path.startswith("@"):
        identifier = path.split("/")[1] if "/" in path else path
        response = YOUTUBE.search().list(part="snippet", q=identifier, type="channel", maxResults=1).execute()
        items = response.get("items", [])
        if items:
            return items[0]["snippet"]["channelId"]
    return None

def get_video_info_batch(video_ids):
    results = []
    for i in range(0, len(video_ids), 50):
        chunk = video_ids[i:i+50]
        response = YOUTUBE.videos().list(part="snippet,statistics", id=",".join(chunk)).execute()
        for item in response.get("items", []):
            results.append({
                "ID –≤–∏–¥–µ–æ": item["id"],
                "–ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞": item["snippet"]["channelTitle"],
                "–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ": item["snippet"]["title"],
                "–û–ø–∏—Å–∞–Ω–∏–µ": item["snippet"].get("description", ""),
                "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": item["statistics"].get("viewCount", "0"),
                "–î–∞—Ç–∞ —Å–±–æ—Ä–∞": datetime.now().strftime('%Y-%m-%d')
            })
    return results

def process_csv_video(file_path, log_widget):
    try:
        df = pd.read_csv(file_path)
        if "url" not in df.columns:
            messagebox.showerror("–û—à–∏–±–∫–∞", "CSV –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'url'")
            return
        urls = df["url"].dropna().unique()
        video_ids = []
        url_map = {}
        for url in urls:
            vid = extract_video_id(url)
            if vid:
                video_ids.append(vid)
                url_map[vid] = url
        infos = get_video_info_batch(video_ids)

        progressbar["maximum"] = len(infos)
        progressbar["value"] = 0
        for idx, info in enumerate(infos):
            current_url_label.config(text=f"–ê–Ω–∞–ª–∏–∑: {url_map.get(info['ID –≤–∏–¥–µ–æ'], '...')}")
            progressbar["value"] = idx + 1
            progressbar.update()
            root.update()

        output = []
        for info in infos:
            output.append({
                "–°—Å—ã–ª–∫–∞": url_map.get(info["ID –≤–∏–¥–µ–æ"], "N/A"),
                "–ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞": info["–ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞"],
                "–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ": info["–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ"],
                "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": info["–ü—Ä–æ—Å–º–æ—Ç—Ä—ã"],
                "–î–∞—Ç–∞ —Å–±–æ—Ä–∞": info["–î–∞—Ç–∞ —Å–±–æ—Ä–∞"]
            })
        out_file = f"video_stats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        pd.DataFrame(output).to_csv(out_file, index=False, encoding='utf-8-sig')
        log_widget.insert(tk.END, f"‚úÖ –ì–æ—Ç–æ–≤–æ! –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {out_file}")
        messagebox.showinfo("–£—Å–ø–µ—Ö", f"–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {out_file}\\n")
    except Exception as e:
        messagebox.showerror("–û—à–∏–±–∫–∞", str(e))

def analyze_channels(file_path, keywords_text, log_widget):
    try:
        df = pd.read_csv(file_path)
        if "channel_url" not in df.columns:
            messagebox.showerror("–û—à–∏–±–∫–∞", "CSV –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'channel_url'")
            return
        urls = df["channel_url"].dropna().unique()
        keywords = [kw.strip().lower() for kw in keywords_text.get("1.0", tk.END).splitlines() if kw.strip()]
        all_rows = []

        progressbar["maximum"] = len(urls)
        progressbar["value"] = 0
        for idx, url in enumerate(urls):
            current_url_label.config(text=f"–ê–Ω–∞–ª–∏–∑ –∫–∞–Ω–∞–ª–∞: {url}")
            progressbar["value"] = idx + 1
            progressbar.update()
            root.update()

            log_widget.insert(tk.END, f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞: {url}")
            channel_id = extract_channel_id(url)
            if not channel_id:
                log_widget.insert(tk.END, f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω: {url}")
                continue
            uploads_playlist = YOUTUBE.channels().list(part="contentDetails", id=channel_id).execute()
            uploads_id = uploads_playlist["items"][0]["contentDetails"]["relatedPlaylists"]["uploads"]
            video_ids = []
            next_token = None
            while len(video_ids) < 20:
                playlist_response = YOUTUBE.playlistItems().list(
                    part="contentDetails",
                    playlistId=uploads_id,
                    maxResults=50,
                    pageToken=next_token
                ).execute()
                for item in playlist_response.get("items", []):
                    video_ids.append(item["contentDetails"]["videoId"])
                    if len(video_ids) >= 20:
                        break
                next_token = playlist_response.get("nextPageToken")
                if not next_token:
                    break
            video_stats = get_video_info_batch(video_ids[:20])
            avg_views = sum(int(v["–ü—Ä–æ—Å–º–æ—Ç—Ä—ã"]) for v in video_stats[:10]) // len(video_stats[:10])
            for v in video_stats:
                for kw in keywords:
                    if kw in v["–û–ø–∏—Å–∞–Ω–∏–µ"].lower():
                        all_rows.append({
                            "–ö–∞–Ω–∞–ª": v["–ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞"],
                            "–°—Å—ã–ª–∫–∞": f"https://youtu.be/{v['ID –≤–∏–¥–µ–æ']}",
                            "–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ": v["–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ"],
                            "–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ": kw,
                            "–°—Ä–µ–¥–Ω–∏–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã": avg_views
                        })
        out_file = f"channel_keyword_stats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        pd.DataFrame(all_rows).to_csv(out_file, index=False, encoding='utf-8-sig')
        log_widget.insert(tk.END, f"‚úÖ –ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {out_file}")
    except Exception as e:
        messagebox.showerror("–û—à–∏–±–∫–∞", str(e))

def choose_file(entry_widget):
    path = filedialog.askopenfilename(filetypes=[("CSV —Ñ–∞–π–ª—ã", "*.csv")])
    entry_widget.delete(0, tk.END)
    entry_widget.insert(0, path)

def main():
    global status_label, current_url_label, progressbar, root

    root = tk.Tk()

    # –°—Ç–∞—Ç—É—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    status_label = tk.Label(root, text="–ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ", font=("Arial", 10, "bold"), fg="blue")
    status_label.pack(pady=(5, 0))

    # –¢–µ–∫—É—â–∏–π –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã–π URL
    current_url_label = tk.Label(root, text="", font=("Arial", 9))
    current_url_label.pack()

    # –û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å
    progressbar = ttk.Progressbar(root, length=400, mode='determinate')
    progressbar.pack(pady=(0, 10))
    root.title("YouTube Stats Scraper")

    notebook = ttk.Notebook(root)
    notebook.pack(fill="both", expand=True)

    # –í–∫–ª–∞–¥–∫–∞ 1 ‚Äî –∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ
    frame1 = tk.Frame(notebook)
    notebook.add(frame1, text="–ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ")

    tk.Label(frame1, text="CSV —Å –∫–æ–ª–æ–Ω–∫–æ–π 'url':").pack()
    entry1 = tk.Entry(frame1, width=60)
    entry1.pack()
    tk.Button(frame1, text="–í—ã–±—Ä–∞—Ç—å —Ñ–∞–π–ª", command=lambda: choose_file(entry1)).pack()

    log1 = tk.Text(frame1, height=15, width=90)
    log1.pack()
    tk.Button(frame1, text="–ó–∞–ø—É—Å—Ç–∏—Ç—å", command=lambda: process_csv_video(entry1.get(), log1)).pack(pady=5)


    # –í–∫–ª–∞–¥–∫–∞ 2 ‚Äî –∞–Ω–∞–ª–∏–∑ –∫–∞–Ω–∞–ª–æ–≤
    frame2 = tk.Frame(notebook)
    notebook.add(frame2, text="–ê–Ω–∞–ª–∏–∑ –∫–∞–Ω–∞–ª–æ–≤")

    tk.Label(frame2, text="CSV —Å –∫–æ–ª–æ–Ω–∫–æ–π 'channel_url':").pack()
    entry2 = tk.Entry(frame2, width=60)
    entry2.pack()
    tk.Button(frame2, text="–í—ã–±—Ä–∞—Ç—å —Ñ–∞–π–ª", command=lambda: choose_file(entry2)).pack()

    tk.Label(frame2, text="–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (–ø–æ –æ–¥–Ω–æ–º—É –≤ —Å—Ç—Ä–æ–∫–µ):").pack()
    keywords_box = tk.Text(frame2, height=5, width=60)
    keywords_box.pack()

    log2 = tk.Text(frame2, height=15, width=90)
    log2.pack()
    tk.Button(frame2, text="–ó–∞–ø—É—Å—Ç–∏—Ç—å", command=lambda: analyze_channels(entry2.get(), keywords_box, log2)).pack(pady=5)


    root.mainloop()

if __name__ == "__main__":
    main()
